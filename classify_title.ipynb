{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7adfba29-1fb8-40d7-a35b-01322509e65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "from typing import Sequence\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "from scraping import (\n",
    "    parse_podcats\n",
    ")\n",
    "from nlp_utils import (\n",
    "    hash_str\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd321c84-9f8b-4043-a786-c136785974ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_podcasts = \"https://lexfridman.com/podcast\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ac44c",
   "metadata": {},
   "source": [
    "Retrieving of the podcasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbac75cf-d5a7-43a1-92b5-091ab18de698",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url_podcasts)\n",
    "html_content = res.content\n",
    "soup_podcasts = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "podcasts = parse_podcats(soup_podcasts)\n",
    "titles = [p.title for p in podcasts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a832ed6",
   "metadata": {},
   "source": [
    "First attempt at classifying the podcasts based on their title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed87427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\" \n",
    "# model_name = \"distilbert-base-uncased\" \n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "labels = ['related to AI', 'not related to AI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94ade93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politics, Family, Real Estate, Fashion, Music, and Life\n",
      "not related to AI\n",
      "Focus, Controversy, Politics, and Relationships\n",
      "not related to AI\n",
      "Perplexity CEO on Future of AI, Search & the Internet\n",
      "not related to AI\n",
      "Physics of Life, Time, Complexity, and Aliens\n",
      "not related to AI\n",
      "Power, Controversy, Betrayal, Truth & Love in Film and Life\n",
      "not related to AI\n",
      "Dangers of Superintelligent AI\n",
      "not related to AI\n",
      "Human Memory, Imagination, Deja Vu, and False Memories\n",
      "not related to AI\n",
      "Jungle, Apex Predators, Aliens, Uncontacted Tribes, and God\n",
      "not related to AI\n",
      "General Relativity, Quantum Mechanics, Black Holes & Aliens\n",
      "not related to AI\n",
      "Judo, Olympics, Winning, Losing, and the Champion Mindset\n",
      "not related to AI\n"
     ]
    }
   ],
   "source": [
    "for title in titles[:10]:\n",
    "\n",
    "    inputs = tokenizer(title, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(**inputs) \n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "    label = labels[predicted_class]\n",
    "\n",
    "    print(f'{title}\\n{label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814c3fe0",
   "metadata": {},
   "source": [
    "**Plan of action:**\n",
    "\n",
    "- Fine tune distilled Bert.\n",
    "    - create a training set.\n",
    "        - Use guest to labellize past titles.\n",
    "        - Use traduction and synonms to do data augmentation.\n",
    "        - scrap some data.\n",
    "    - Do the fine tuning\n",
    "- Test it of a validation set.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf032e27",
   "metadata": {},
   "source": [
    "#### Training dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a038dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_podcast = pd.DataFrame(podcasts)\n",
    "\n",
    "\n",
    "cols_to_pp = [\"guest\", \"title\"]\n",
    "\n",
    "for col in cols_to_pp:\n",
    "    df_podcast[col] = np.vectorize(lambda title: unidecode(title))(df_podcast[col])\n",
    "    df_podcast[col] = df_podcast[col].str.lower()\n",
    "\n",
    "# df_podcast.insert(0, 'id', df_podcast.reset_index(drop=True).index + 1)\n",
    "hash_str_vec = np.vectorize(hash_str)\n",
    "df_podcast.insert(0, 'id', hash_str_vec(df_podcast.guest + df_podcast.title))\n",
    "\n",
    "assert df_podcast.id.nunique() == len(df_podcast), \"colision in the hashing to create unique id!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86de5a9b",
   "metadata": {},
   "source": [
    "The positive titles will be:\n",
    "- titles of podcast whose guest is a AI/ML/DS person I am interested in.\n",
    "\n",
    "or\n",
    "\n",
    "- titles with ML terms that I will validate by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "de92e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_science_guests = [\n",
    "    \"Aravind Srinivas\",\n",
    "    \"Andrej Karpathy\",\n",
    "    \"Sam Altman\",\n",
    "    \"Yann LeCun\",\n",
    "    \"Joscha Bach\",\n",
    "    \"Max Tegmark\",\n",
    "    \"Noam Brown\",\n",
    "    \"Rana el Kaliouby\",\n",
    "    \"Ray Kurzweil\",\n",
    "    \"Oriol Vinyals\",\n",
    "    \"Demis Hassabis\",\n",
    "    \"Travis Oliphant\",\n",
    "    \"Jay McClelland\",\n",
    "    \"Douglas Lenat\",\n",
    "    \"Wojciech Zaremba\",\n",
    "    \"Ishan Misra\",\n",
    "    \"Risto Miikkulainen\",\n",
    "    \"Max Tegmark\",\n",
    "    \"Dan Kokotov\",\n",
    "    \"Michael Littman\",\n",
    "    \"Charles Isbell\",\n",
    "    \"FranÃ§ois Chollet\",\n",
    "    \"Dileep George\",\n",
    "    \"Jitendra Malik\",\n",
    "    \"Sergey Levine\",\n",
    "    \"Matt Botvinick\",\n",
    "    \"Ben Goertzel\",\n",
    "    \"Dawn Song\",\n",
    "    \"Ilya Sutskever\",\n",
    "    \"Daphne Koller\",\n",
    "    \"David Silver\",\n",
    "    \"Marcus Hutter\",\n",
    "    \"Michael I. Jordan\",\n",
    "    \"Andrew Ng\",\n",
    "    \"Gary Marcus\",\n",
    "    \"Peter Norvig\",\n",
    "    \"Regina Barzilay\",\n",
    "    \"Jeremy Howard\",\n",
    "    \"Rajat Monga\",\n",
    "    \"Ian Goodfellow\",\n",
    "    \"Greg Brockman\",\n",
    "    \"Tomaso Poggio\",\n",
    "    \"Juergen Schmidhuber\",\n",
    "    \"Pieter Abbeel\",\n",
    "    \"Stuart Russell\",\n",
    "    \"Yoshua Bengio\",\n",
    "    \"Vladimir Vapnik\",\n",
    "]\n",
    "data_science_guests_pp = [unidecode(guest).lower() for guest in data_science_guests]\n",
    "\n",
    "words_to_check = [\n",
    "    \"Neural Nets\",\n",
    "    \"neural networks\",\n",
    "    \"Deep Learning\",\n",
    "    \"Machine learning\",\n",
    "    \"Reinforcement Learning\",\n",
    "    \"Data science\",\n",
    "    \"AI\",\n",
    "    \"AGI\",\n",
    "    \"artificial intelligence\"\n",
    "]\n",
    "words_to_check_pp = [unidecode(word).lower() for word in words_to_check]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeec3bf",
   "metadata": {},
   "source": [
    "Manual validation based on regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "20a21555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_guest_relevant(guest_candidate: str, data_science_guests: Sequence[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Check if any data science guest is contained in the given guest_candidate.\n",
    "    Necessary because some guest_candidate contained multiple guests.\n",
    "    \"\"\"\n",
    "    return any(relevant_guest in guest_candidate for relevant_guest in data_science_guests)\n",
    "\n",
    "is_guest_relevant_vec = np.vectorize(\n",
    "    is_guest_relevant,\n",
    "    excluded=['data_science_guests'],\n",
    "    signature='(),(n)->()'\n",
    ")\n",
    "df_podcast[\"has_relevant_guest\"] = is_guest_relevant_vec(df_podcast.guest, data_science_guests_pp).astype(int)\n",
    "\n",
    "re_not_character_or_beginning = r'(?:[^a-z]|^)'\n",
    "re_not_character_or_end = r'(?:[^a-z]|$)'\n",
    "\n",
    "pattern = (\n",
    "    re_not_character_or_beginning +\n",
    "    (f'{re_not_character_or_end}|{re_not_character_or_beginning}').join(words_to_check_pp) + \n",
    "    re_not_character_or_end\n",
    ")\n",
    "df_podcast[\"has_ml_word\"] = df_podcast.title.str.contains(pattern, case=False, regex=True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5d726283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98195452: roman yampolskiy\n",
      "dangers of superintelligent ai\n",
      "\n",
      "86440844: guillaume verdon\n",
      "beff jezos, e/acc movement, physics, computation & agi\n",
      "\n",
      "68071720: elon musk\n",
      "war, ai, aliens, politics, physics, video games, and humanity\n",
      "\n",
      "37124594: george hotz\n",
      "tiny corp, twitter, ai safety, self-driving, and god\n",
      "\n",
      "60879511: marc andreessen\n",
      "future of the internet, technology, and ai\n",
      "\n",
      "99072863: mark zuckerberg\n",
      "future of ai at meta, facebook, instagram, and whatsapp\n",
      "\n",
      "41763735: chris lattner\n",
      "future of programming and ai\n",
      "\n",
      "68276965: manolis kellis\n",
      "evolution of human civilization and superintelligent ai\n",
      "\n",
      "62663336: eliezer yudkowsky\n",
      "dangers of ai and the end of human civilization\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = 0\n",
    "increment = 9\n",
    "\n",
    "df_to_check = df_podcast.loc[\n",
    "    (df_podcast.has_relevant_guest == 0) & (df_podcast.has_ml_word == 1) \n",
    "]\n",
    "\n",
    "for _, (id, guest, title) in df_to_check.loc[:,[\"id\", \"guest\", \"title\"]].iloc[batch*increment: batch*increment + increment].iterrows():\n",
    "    print(f\"{id}: {guest}\\n{title}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5415d1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_positive_id = [\n",
    "    98195452,\n",
    "    41763735,\n",
    "    68276965,\n",
    "    59789751,\n",
    "    60449962,\n",
    "    93271390,\n",
    "    79695739,\n",
    "    31945141,\n",
    "    58779362,\n",
    "]\n",
    "\n",
    "df_podcast[\"manual_label\"] = df_podcast.id.isin(manual_positive_id).astype(int)\n",
    "\n",
    "df_podcast[\"label\"] = (\n",
    "    df_podcast.manual_label | df_podcast.has_relevant_guest\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "58bd74bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>guest</th>\n",
       "      <th>title</th>\n",
       "      <th>url_transcript</th>\n",
       "      <th>has_ml_word</th>\n",
       "      <th>has_relevant_guest</th>\n",
       "      <th>manual_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>26277046</td>\n",
       "      <td>ray dalio</td>\n",
       "      <td>principles</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>12126081</td>\n",
       "      <td>max tegmark</td>\n",
       "      <td>ai and physics</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>73511281</td>\n",
       "      <td>nick lane</td>\n",
       "      <td>origin of life, evolution, aliens, and biology</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>80058926</td>\n",
       "      <td>joscha bach</td>\n",
       "      <td>artificial consciousness</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>29278313</td>\n",
       "      <td>jeffrey shainline</td>\n",
       "      <td>optoelectronic intelligence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>76164777</td>\n",
       "      <td>joscha bach</td>\n",
       "      <td>life, intelligence, consciousness, ai &amp; the fu...</td>\n",
       "      <td>https://lexfridman.com/joscha-bach-3-transcript</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>39097670</td>\n",
       "      <td>natalya bailey</td>\n",
       "      <td>rocket engines and electric spacecraft propulsion</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>99900770</td>\n",
       "      <td>charles isbell</td>\n",
       "      <td>computing, ai &amp; race in america</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>13010577</td>\n",
       "      <td>gary marcus</td>\n",
       "      <td>hybrid of deep learning and symbolic ai</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>94642723</td>\n",
       "      <td>sean carroll</td>\n",
       "      <td>quantum mechanics and many-worlds</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id              guest  \\\n",
       "381  26277046          ray dalio   \n",
       "281  12126081        max tegmark   \n",
       "118  73511281          nick lane   \n",
       "335  80058926        joscha bach   \n",
       "211  29278313  jeffrey shainline   \n",
       "44   76164777        joscha bach   \n",
       "279  39097670     natalya bailey   \n",
       "301  99900770     charles isbell   \n",
       "392  13010577        gary marcus   \n",
       "388  94642723       sean carroll   \n",
       "\n",
       "                                                 title  \\\n",
       "381                                         principles   \n",
       "281                                     ai and physics   \n",
       "118     origin of life, evolution, aliens, and biology   \n",
       "335                           artificial consciousness   \n",
       "211                        optoelectronic intelligence   \n",
       "44   life, intelligence, consciousness, ai & the fu...   \n",
       "279  rocket engines and electric spacecraft propulsion   \n",
       "301                    computing, ai & race in america   \n",
       "392            hybrid of deep learning and symbolic ai   \n",
       "388                  quantum mechanics and many-worlds   \n",
       "\n",
       "                                      url_transcript  has_ml_word  \\\n",
       "381                                             None            0   \n",
       "281                                             None            1   \n",
       "118                                             None            0   \n",
       "335                                             None            0   \n",
       "211                                             None            0   \n",
       "44   https://lexfridman.com/joscha-bach-3-transcript            1   \n",
       "279                                             None            0   \n",
       "301                                             None            1   \n",
       "392                                             None            1   \n",
       "388                                             None            0   \n",
       "\n",
       "     has_relevant_guest  manual_label  label  \n",
       "381                   0             0      0  \n",
       "281                   1             0      1  \n",
       "118                   0             0      0  \n",
       "335                   1             0      1  \n",
       "211                   0             0      0  \n",
       "44                    1             0      1  \n",
       "279                   0             0      0  \n",
       "301                   1             0      1  \n",
       "392                   1             0      1  \n",
       "388                   0             0      0  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_podcast.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
