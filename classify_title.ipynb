{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7adfba29-1fb8-40d7-a35b-01322509e65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pierre/anaconda3/envs/lexscraper/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "from utils import (\n",
    "    parse_podcats, parse_transcript\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd321c84-9f8b-4043-a786-c136785974ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_podcasts = \"https://lexfridman.com/podcast\"\n",
    "url_yann_lecun = \"https://lexfridman.com/yann-lecun-3-transcript\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbac75cf-d5a7-43a1-92b5-091ab18de698",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url_podcasts)\n",
    "html_content = res.content\n",
    "soup_podcasts = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "podcasts = parse_podcats(soup_podcasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32169571-8ef4-420a-b6a1-673440f5bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [p.title for p in podcasts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ed87427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\" \n",
    "# model_name = \"distilbert-base-uncased\" \n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "labels = ['related to AI', 'not related to AI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e65bc54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = titles[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94ade93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politics, Family, Real Estate, Fashion, Music, and Life\n",
      "not related to AI\n",
      "Focus, Controversy, Politics, and Relationships\n",
      "not related to AI\n",
      "Perplexity CEO on Future of AI, Search & the Internet\n",
      "not related to AI\n",
      "Physics of Life, Time, Complexity, and Aliens\n",
      "not related to AI\n",
      "Power, Controversy, Betrayal, Truth & Love in Film and Life\n",
      "not related to AI\n",
      "Dangers of Superintelligent AI\n",
      "not related to AI\n",
      "Human Memory, Imagination, Deja Vu, and False Memories\n",
      "not related to AI\n",
      "Jungle, Apex Predators, Aliens, Uncontacted Tribes, and God\n",
      "not related to AI\n",
      "General Relativity, Quantum Mechanics, Black Holes & Aliens\n",
      "not related to AI\n",
      "Judo, Olympics, Winning, Losing, and the Champion Mindset\n",
      "not related to AI\n"
     ]
    }
   ],
   "source": [
    "for title in titles[:10]:\n",
    "\n",
    "    inputs = tokenizer(title, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    outputs = model(**inputs) \n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "    label = labels[predicted_class]\n",
    "\n",
    "    print(f'{title}\\n{label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814c3fe0",
   "metadata": {},
   "source": [
    "- Fine tune distilled Bert.\n",
    "    - create a training set.\n",
    "        - Use guest to labellize past titles.\n",
    "        - Use traduction and synonms to do data augmentation.\n",
    "        - scrap some data.\n",
    "    - Do the fine tuning\n",
    "- Test it of a validation set.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
